<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description"
    content="A foundation model for visual navigation that generalizes across environments and robots, and can be readily adapted to downstream tasks.">
  <meta name="keywords" content="ViNT, robotics, foundation model">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>ViNT: A Foundation Model for Visual Navigation</title>

  <!-- Google tag (gtag.js) -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-RP4PXW5RP7"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());

    gtag('config', 'G-RP4PXW5RP7');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>

<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <a class="navbar-item" href="https://cs.berkeley.edu/~shah">
          <span class="icon">
            <i class="fas fa-home"></i>
          </span>
        </a>

        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://sites.google.com/view/drive-any-robot">
              GNM: A General Navigation Model to Drive Any Robot
            </a>
            <a class="navbar-item" href="https://sites.google.com/view/viking-release">
              ViKiNG: Kilometer-Scale Navigatin with Geographic Hints
            </a>
            <a class="navbar-item" href="https://sites.google.com/view/lmnav">
              LM-Nav: Navigation with Pre-Trained Language and Vision Models
            </a>
            <a class="navbar-item" href="https://sites.google.com/view/fastrlap">
              FastRLAP: High-Speed Driving via Real-World Online RL
            </a>
          </div>
        </div>
      </div>

    </div>
  </nav>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title">ViNT: A Foundation Model for Visual Navigation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://cs.berkeley.edu/~shah">Dhruv Shah</a><sup>&#8224;</sup>,</span>
              <span class="author-block">
                <a href="">Ajay Sridhar</a><sup>&#8224;</sup>,</span>
              <span class="author-block">
                <a href="https://dashora7.github.io">Nitish Dashora</a><sup>&#8224;</sup>,
              </span> <br>
              <span class="author-block">
                <a href="https://kylesta.ch">Kyle Stachowicz</a>,
              </span>
              <span class="author-block">
                <a href="https://kevin.black">Kevin Black</a>,
              </span>
              <span class="author-block">
                <a href="https://sites.google.com/view/noriaki-hirose/">Noriaki Hirose</a>,
              </span>
              <span class="author-block">
                <a href="https://cs.berkeley.edu/~svlevine">Sergey Levine</a>
              </span>
            </div>

            <div class="is-size-6 publication-authors">
              <span class="author-block">UC Berkeley</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- PDF Link. -->
                <span class="link-block">
                  <a href="https://arxiv.org/pdf/2306.xxxx" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2306.xxxx" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
                <!-- Video Link. -->
                <span class="link-block">
                  <a href="https://www.youtube.com/watch?v=MrKrnHhk8IA"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-youtube"></i>
                    </span>
                    <span>Video</span>
                  </a>
                </span>
                <!-- Code Link. -->
                <span class="link-block">
                  <a href="https://github.com/PrieureDeSion/visualnav-transformer"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>
                <!-- Dataset Link. -->

              </div>

            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <video id="teaser" autoplay muted loop playsinline height="100%">
          <source src="./static/videos/teaser.mov" type="video/mp4">
        </video>
      </div>
    </div>
  </section>

  <!-- vint_videos_bww1.mp4
            vint_videos_bww3.mp4
            vint_videos_carla.mp4
            vint_videos_go1_outside.mp4
            vint_videos_pedestrian.mp4
            vint_videos_rfs.mp4
            vint_videos_soda3_both.mp4
            vint_videos_soda3_left.mp4
            vint_videos_go_inside_1.mp4
            vint_videos_go1_inside_2.mp4
            vint_videos_soda3_right.mp4 -->

  <!-- Results Carousel -->
  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" id="steve" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_bww1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" id="chair-tp" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_go1_outside.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_soda3_left.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-fullbody">
            <video poster="" id="fullbody" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_rfs.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-blueshirt">
            <video poster="" id="blueshirt" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_go_inside_1.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-mask">
            <video poster="" id="mask" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_pedestrian.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-coffee">
            <video poster="" id="coffee" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_carla.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-toby">
            <video poster="" id="toby" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_go1_inside_2.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-shiba">
            <video poster="" id="shiba" autoplay controls muted loop playsinline height="100%">
              <source src="./static/videos/vint_videos_soda3_right.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Abstract. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              General-purpose pre-trained models ("foundation models") have enabled practitioners to produce
              generalizable solutions for individual machine learning problems with datasets that are significantly
              smaller than those required for learning from scratch. Such models are typically trained on large and
              diverse datasets with weak supervision, consuming much more training data than is available for any
              individual downstream application.
            </p>
            <p>
              In this paper, we describe the Visual Navigation Transformer (ViNT), a <i>foundation model</i> that aims
              to bring the success of general-purpose pre-trained models to vision-based robotic navigation. ViNT is
              trained with a general goal-reaching objective that can be used with any navigation dataset, and employs a
              flexible Transformer-based architecture to learn navigational affordances and enable efficient adaptation
              to a variety of downstream navigational tasks. ViNT is trained on a number of existing navigation
              datasets, comprising hundreds of hours of robotic navigation from a variety of different robotic
              platforms, and exhibits <i>positive transfer</i>, outperforming specialist models trained on singular
              datasets.
            </p>
            <p>
              ViNT can be augmented with diffusion-based subgoal proposals to explore novel environments, and can solve
              kilometer-scale navigation problems when equipped with long-range heuristics. ViNT can also be adapted to
              novel task specifications with a technique inspired by prompt-tuning, where the goal encoder is replaced
              by an encoding of another task modality (e.g., GPS waypoints or routing commands) embedded into the
              same space of goal tokens. This flexibility and ability to accommodate a variety of downstream problem
              domains establishes ViNT as an effective foundation model for mobile robotics.
            </p>
          </div>
        </div>
      </div>

      <!--/ Abstract. -->

      <!-- Paper video. -->
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Summary Video</h2>
          <div class="publication-video">
            <!---TODO Dhruv: put video link here-->
            <iframe src="https://www.youtube.com/embed/ICeD6iOglKc?rel=0&amp;showinfo=0" frameborder="0"
              allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!--/ Paper video. -->

  <section class="section">
    <div class="container is-max-desktop">
      <!-- Method overview -->
      <center>
        <h2 class="title is-3">Overview</h2>
      </center>
      <br>
      <div class="columns is-centered has-text-centered">

        <div class="column">
          <div class="content">
            <h2 class="title is-4">ViNT Architecture</h2>
            <p>
              ViNT uses a Transformer-based architecture to encode visual observations and goals, and predicts
              temporal distance and normalized actions in an embodiment-agnostic manner.
            </p>
            <figure id="architecture">
              <img src="./static/images/vint_architecture.jpg" alt="ViNT architecture" />
            </figure>
          </div>
        </div>

        <div class="column">
          <div class="content">
            <h2 class="title is-4">Adaptation</h2>
            <p>
              ViNT can be fine-tuned by a mechanism akin to <i>prompt-tuning</i>, to support alternative goal
              modalities.
            </p>
            <figure id="adaptation">
              <img src="./static/images/vint_adaptation.jpg" alt="ViNT adaptation" />
            </figure>
          </div>
        </div>

      </div>
      <div class="column is-centered has-text-centered">
        <div class="content">
          <h2 class="title is-4">Search Overview</h2>
          <p>
            ViNT can explore <i>previously unseen</i> environments by employing a topological graph-based global
            planner. An image-to-image diffusion model proposes diverse exploration targets which are spatially grounded
            using ViNT (yellow), and scored using a goal-directed heuristic <i>h</i>. Subgoals are added to the
            topological graph and executed using the ViNT policy.
          </p>
          <figure id="subgoal">
            <img src="./static/images/vint_search_overview.jpg" alt="Overview of heuristic-guided search with ViNT" />
          </figure>
        </div>
  </section>




  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@article{shah2023vint,
  author    = {Dhruv Shah and Ajay Sridhar and Nitish Dashora 
               and Kyle Stachowicz and Kevin Black and Noriaki Hirose and Sergey Levine},
  title     = {{ViNT: A Foundation Model for Visual Navigation}},
  journal   = {arXiv pre-print},
  year      = {2023},
  url       = {https://arxiv.org/abs/2306.xxxx},
}</code></pre>
    </div>
  </section>

  <center class="is-size-10">
    The website template was borrowed from <a href="https://nerfies.github.io>" class="external-link"><span
        class="dnerf">Nerfies</span></a>.
  </center>
</body>

</html>